# ![Phinx](media/phinx.png)  
[![Chat on Discord](https://img.shields.io/discord/754884471324672040?style=for-the-badge)](https://discord.gg/tPWjMwK) [![Follow on Bluesky](https://img.shields.io/badge/Bluesky-tinyBigGAMES-blue?style=for-the-badge&logo=bluesky)](https://bsky.app/profile/tinybiggames.com) [![Reddit](https://img.shields.io/badge/Reddit-Phinx-red?style=for-the-badge&logo=reddit)](https://www.reddit.com/r/Phinx/)


### A High-Performance AI Inference Library for ONNX and Phi-4

**Phinx** is an advanced AI inference library that leverages **ONNX Runtime GenAI** and the **Phi-4 Multimodal ONNX** model for fast, efficient, and scalable AI applications. Designed for developers seeking seamless integration of generative and multimodal AI, Phinx offers an optimized and flexible runtime environment with robust performance.

## ğŸš€ Key Features

- **ONNX-Powered Inference** â€“ Efficient execution of Phi-4 models using ONNX Runtime GenAI.
- **Multimodal AI** â€“ Supports text, image, and multi-input inference for diverse AI tasks.
- **Optimized Performance** â€“ Accelerated inference leveraging ONNX optimizations for speed and efficiency.
- **Developer-Friendly API** â€“ Simple yet powerful APIs for easy integration into **Delphi, Python, and other platforms**.
- **Self-Contained & Virtualized** â€“ The `Phinx.model` file acts as a **virtual folder**, bundling **Phi-4 ONNX model files** and all dependencies into a single, portable format.

Phinx is ideal for AI research, creative applications, and production-ready generative AI solutions. Whether you're building **chatbots, AI-powered content generation tools, or multimodal assistants**, Phinx delivers the **speed and flexibility** you need!


## ğŸ“‚ Phinx Model File Format (`Phinx.model`)

The **Phinx.model** format is a specialized file structure for storing **ONNX-based machine learning models**, optimized for **CUDA-powered inference**. It encapsulates all essential components, ensuring seamless model execution.

### ğŸ”¹ Key Benefits

1. **Self-Contained & Virtualized**
   - Acts as a **virtual folder** within the application.
   - Bundles **Phi-4 ONNX model files** and dependencies for portability.

2. **Optimized for CUDA Inference**
   - Designed for **GPU acceleration**, delivering high-performance AI execution.
   - Ensures fast loading and efficient CUDA computations.

3. **Structured & Extensible**
   - Stores **model weights, metadata, configuration parameters, and dependencies** in a well-organized manner.
   - Future-proof design allows for additional configurations and optimizations.

4. **Simplified Deployment**
   - All required files are consolidated into a single **`.model`** file.
   - Eliminates external dependency management for **plug-and-play usability**.

## ğŸ›  Getting Started

### ğŸ”§ System Requirements

- **GPU Requirements:** CUDA-compatible NVIDIA GPU with **8â€“12GB VRAM**.
- **Storage Requirements:** At least **7GB** of free disk space.

### ğŸ“¥ Download Model

Get the **Phinx Model** from Hugging Face:
[ğŸ“‚ Download Phinx Model](https://huggingface.co/tinybiggames/Phinx/resolve/main/Phinx.model?download=true)

### ğŸ— Setup Instructions

1. Place the downloaded model in your preferred directory.
   - Example path: `C:/LLM/PHINX/repo`
2. Ensure you have a **Delphi version that supports Win64 and Unicode**.
3. Developed with: **Delphi 12.2**
4. Tested on: **Windows 11 (24H2)**
5. Refer to `UTestbed.pas` for usage notes and check the examples.

## ğŸš§ Project Status

> **âš ï¸ Note:** This repository is currently in the setup phase. While documentation is being prepared, the **code is fully functional and stable**. Stay tunedâ€”this README and additional resources will be updated soon! ğŸš€

## ğŸ“º Media
ğŸŒŠ Deep Dive Podcast  
Discover in-depth discussions and insights about Sophora and its innovative features. ğŸš€âœ¨

ğŸ¥ Phinx Feature Videos  
Explore videos showcasing the powerful capabilities of the Phinx library, including tutorials, demonstrations, and real-world applications. ğŸ¬ğŸ”¥


https://github.com/user-attachments/assets/d58bc2d1-bef5-458d-9377-6b1235c51972


https://github.com/user-attachments/assets/c166106a-4266-4b0f-9d95-42d1b2cc0921



## ğŸ’¬ Support and Resources

- ğŸ **Report Issues:** [Issue Tracker](https://github.com/tinyBigGAMES/Phinx/issues)
- ğŸ’¬ **Join the Community:** [Forum](https://github.com/tinyBigGAMES/Phinx/discussions) | [Discord](https://discord.gg/tPWjMwK)
- ğŸ“š **Learn Delphi:** [Learn Delphi](https://learndelphi.org)

## ğŸ¤ Contributing

Contributions to **âœ¨ Phinx** are highly encouraged! ğŸŒŸ  
Ways to contribute:
- ğŸ› **Report Bugs:** Help us improve by submitting issues.
- ğŸ’¡ **Suggest Features:** Share ideas to enhance Phinx.
- ğŸ”§ **Create Pull Requests:** Improve the libraryâ€™s capabilities.

### ğŸ† Contributors

<a href="https://github.com/tinyBigGAMES/Phinx/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=tinyBigGAMES/Phinx&max=250&columns=10&anon=1" />
</a>

## ğŸ“œ License

Phinx is distributed under the **BSD-3-Clause License**, allowing redistribution and use in both source and binary forms, with or without modification.  
See the [ğŸ“œ LICENSE](https://github.com/tinyBigGAMES/Phinx?tab=BSD-3-Clause-1-ov-file#BSD-3-Clause-1-ov-file) for more details.

## ğŸ’– Support & Sponsorship

If you find **Phinx** useful, please consider [sponsoring this project](https://github.com/sponsors/tinyBigGAMES). Your support helps sustain development, improve features, and keep the project thriving.

### Other ways to contribute:
- â­ **Star the repo** â€“ It helps increase visibility.
- ğŸ“¢ **Spread the word** â€“ Share Phinx with your network.
- ğŸ› **Report bugs** â€“ Help identify issues.
- ğŸ”§ **Submit fixes** â€“ Found a bug? Fix it and contribute!
- ğŸ’¡ **Suggest enhancements** â€“ Share ideas for improvements.

Every contribution, big or small, helps make **Phinx** better. Thank you for your support! ğŸš€

---

 âš¡ Phinx â€“ Powering AI with Phi-4, ONNX & CUDA, Seamlessly and Efficiently! âš¡

<p align="center">
  <img src="media/delphi.png" alt="Delphi">
</p>
<h5 align="center">Made with â¤ï¸ in Delphi</h5>

